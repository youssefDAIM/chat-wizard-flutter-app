
import { useState, useRef, useEffect } from "react";
import { Button } from "@/components/ui/button";
import { Input } from "@/components/ui/input";
import { useToast } from "@/components/ui/use-toast";
import { Send } from "lucide-react";
import ChatMessage from "@/components/ChatMessage";
import ModelSelector from "@/components/ModelSelector";

interface ChatPageProps {
  username: string;
}

interface Message {
  id: string;
  sender: "user" | "ai";
  text: string;
  timestamp: Date;
}

const ChatPage = ({ username }: ChatPageProps) => {
  const [messages, setMessages] = useState<Message[]>([
    {
      id: "welcome",
      sender: "ai",
      text: `Hello ${username}, how can I assist you today?`,
      timestamp: new Date(),
    },
  ]);
  const [input, setInput] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const [selectedModel, setSelectedModel] = useState("gpt-3.5");
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const { toast } = useToast();

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  const handleSendMessage = async (e: React.FormEvent) => {
    e.preventDefault();
    
    if (!input.trim()) return;
    
    const userMessage: Message = {
      id: Date.now().toString(),
      sender: "user",
      text: input,
      timestamp: new Date(),
    };
    
    setMessages((prev) => [...prev, userMessage]);
    setInput("");
    setIsLoading(true);
    
    // Simulate AI response
    try {
      // In a real app, you would make an API call to an LLM service here
      setTimeout(() => {
        const aiResponse: Message = {
          id: (Date.now() + 1).toString(),
          sender: "ai",
          text: generateDummyResponse(input, selectedModel),
          timestamp: new Date(),
        };
        
        setMessages((prev) => [...prev, aiResponse]);
        setIsLoading(false);
      }, 1500);
    } catch (error) {
      setIsLoading(false);
      toast({
        title: "Error",
        description: "Failed to get response from AI",
        variant: "destructive",
      });
    }
  };

  const generateDummyResponse = (question: string, model: string): string => {
    // This is a simple dummy response generator
    // In a real app, this would be replaced with actual LLM API calls
    
    if (question.toLowerCase().includes("hello") || question.toLowerCase().includes("hi")) {
      return `Hello! I'm a simulated ${model} AI. How can I help you today?`;
    }
    
    if (question.toLowerCase().includes("name")) {
      return `I'm a ${model} AI assistant, created to help answer your questions.`;
    }
    
    if (question.toLowerCase().includes("weather")) {
      return "I don't have real-time weather data in this demo. In a real implementation, I could connect to a weather API to provide that information.";
    }
    
    return `This is a simulated response from ${model}. In a real application, this would be generated by an actual LLM API. Your message was: "${question}"`;
  };

  return (
    <div className="h-screen flex flex-col">
      <header className="bg-white/80 backdrop-blur-sm shadow p-4">
        <div className="container mx-auto flex justify-between items-center">
          <h1 className="text-xl font-bold">AI Chat</h1>
          <div className="flex items-center gap-4">
            <ModelSelector 
              selectedModel={selectedModel}
              onSelectModel={setSelectedModel}
            />
            <div className="text-sm font-medium">User: {username}</div>
          </div>
        </div>
      </header>
      
      <main className="flex-1 overflow-y-auto p-4 bg-background/80">
        <div className="container mx-auto max-w-4xl">
          <div className="space-y-4 py-4">
            {messages.map((message) => (
              <ChatMessage 
                key={message.id} 
                message={message} 
              />
            ))}
            {isLoading && (
              <div className="ai-message">
                <div className="flex space-x-2">
                  <div className="h-2 w-2 bg-primary rounded-full animate-pulse"></div>
                  <div className="h-2 w-2 bg-primary rounded-full animate-pulse delay-75"></div>
                  <div className="h-2 w-2 bg-primary rounded-full animate-pulse delay-150"></div>
                </div>
              </div>
            )}
            <div ref={messagesEndRef} />
          </div>
        </div>
      </main>
      
      <footer className="bg-white/80 backdrop-blur-sm p-4 border-t">
        <div className="container mx-auto max-w-4xl">
          <form onSubmit={handleSendMessage} className="flex gap-2">
            <Input
              value={input}
              onChange={(e) => setInput(e.target.value)}
              placeholder="Type your message..."
              className="flex-1"
              disabled={isLoading}
            />
            <Button type="submit" disabled={isLoading || !input.trim()}>
              <Send className="h-4 w-4" />
              <span className="sr-only">Send message</span>
            </Button>
          </form>
        </div>
      </footer>
    </div>
  );
};

export default ChatPage;
